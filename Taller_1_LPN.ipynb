{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Vop-mLHyHl2rimxUgfUOaH1mYFsiiuNu",
      "authorship_tag": "ABX9TyMMrMa5Yf1PykR+FuJAgWAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarimso/Lenguaje-Natural/blob/main/Taller_1_LPN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***Análisis de Sentimientos con Reseñas de Alimentos de Amazon.***\n",
        "\n",
        "Práctica Integral de NLP con el Dataset \"Amazon Reviews\"\n",
        "\n",
        "Este notebook aplica las técnicas de la Sesión 1 (Spacy, NLTK,\n",
        "análisis de sentimientos) sobre el archivo 'amazonreviews.tsv'.\n"
      ],
      "metadata": {
        "id": "qLH0KRonjTqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos los datos, para esta practica usaremos desde kaggle el dataset **\"Amazon Reviews\"**"
      ],
      "metadata": {
        "id": "hqHNqCiZl13J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"yasash/nlp-udemy-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg4m7raJkuTg",
        "outputId": "880907e1-922f-4ca0-91ba-3d8367425943"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/nlp-udemy-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sección 1:** Analisis Exploratorio del Corpus de reseñas\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "39g5vlY9lexP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1: ***Preparación e Importaciones***"
      ],
      "metadata": {
        "id": "SMOjhCF6mTXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cargar el modelo de Spacy en inglés\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "IeLrlimMj7AZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2: ***Carga y Limpieza de los Datos***"
      ],
      "metadata": {
        "id": "pLDn_T-1m3hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los datos desde el archivo TSV (Tab-Separated Values)\n",
        "df = pd.read_csv('/root/.cache/kagglehub/datasets/yasash/nlp-udemy-dataset/versions/1/amazonreviews.tsv', sep='\\t')\n",
        "df.columns = ['label', 'review'] # Renombramos las columnas para mayor claridad\n",
        "\n",
        "# Eliminamos filas con reseñas nulas o vacías\n",
        "df.dropna(inplace=True)\n",
        "df = df[df['review'].str.strip() != '']\n",
        "\n",
        "print(f\"\\nSe han cargado {len(df)} reseñas del archivo 'amazonreviews.tsv'.\")\n",
        "print(\"\\nEjemplo de los datos:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaOqLFM0mi49",
        "outputId": "04af29dd-de74-4aa5-b186-93065b544dfa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Se han cargado 10000 reseñas del archivo 'amazonreviews.tsv'.\n",
            "\n",
            "Ejemplo de los datos:\n",
            "  label                                             review\n",
            "0   pos  Stuning even for the non-gamer: This sound tra...\n",
            "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
            "2   pos  Amazing!: This soundtrack is my favorite music...\n",
            "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
            "4   pos  Remember, Pull Your Jaw Off The Floor After He...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3: ***Procesamiento y Análisis Básico con Spacy***"
      ],
      "metadata": {
        "id": "d9IViu9sncdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomaremos la primera reseña para un análisis detallado.\n",
        "# Usamos nlp.pipe para procesar textos de forma eficiente, aunque aquí solo es uno.\n",
        "primera_resena_texto = df['review'].iloc[0]\n",
        "doc = nlp(primera_resena_texto)\n",
        "\n",
        "# Conteo básico de tokens y oraciones\n",
        "tokens_totales = len(doc)\n",
        "oraciones = list(doc.sents)\n",
        "oraciones_totales = len(oraciones)\n",
        "\n",
        "print(f\"\\n--- Análisis de la primera reseña ---\")\n",
        "print(f\"Texto: '{primera_resena_texto}'\")\n",
        "print(f\"Número de tokens: {tokens_totales}\")\n",
        "print(f\"Número de oraciones: {oraciones_totales}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEFThZaHnXZ3",
        "outputId": "9dd6aa60-e560-4810-efe1-fdd4bca7c4dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Análisis de la primera reseña ---\n",
            "Texto: 'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'\n",
            "Número de tokens: 89\n",
            "Número de oraciones: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis detallado de la primera oración de la reseña\n",
        "primera_oracion = oraciones[0]\n",
        "print(\"\\nAnálisis detallado de la primera oración:\")\n",
        "print(f\"{'Texto':<15} {'POS':<10} {'Dependencia':<15} {'Lema'}\")\n",
        "print(\"-\" * 55)\n",
        "for token in primera_oracion:\n",
        "    if not token.is_space:\n",
        "        print(f\"{token.text:<15} {token.pos_:<10} {token.dep_:<15} {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VQPBMHOonh9",
        "outputId": "6e823102-c1ff-4128-c6cf-dda0b6607c22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Análisis detallado de la primera oración:\n",
            "Texto           POS        Dependencia     Lema\n",
            "-------------------------------------------------------\n",
            "Stuning         VERB       advcl           stun\n",
            "even            ADV        advmod          even\n",
            "for             ADP        prep            for\n",
            "the             DET        det             the\n",
            "non             NOUN       pobj            non\n",
            "-               NOUN       pobj            -\n",
            "gamer           NOUN       pobj            gamer\n",
            ":               PUNCT      punct           :\n",
            "This            DET        det             this\n",
            "sound           NOUN       amod            sound\n",
            "track           NOUN       nsubj           track\n",
            "was             AUX        ROOT            be\n",
            "beautiful       ADJ        acomp           beautiful\n",
            "!               PUNCT      punct           !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4: ***Busqueda de Patrones con Matcher***"
      ],
      "metadata": {
        "id": "r7pNjah-o2ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscaremos patrones comunes en reseñas, como \"sound track\" o \"video game\".\n",
        "print(\"\\n--- Búsqueda de patrones con Matcher en la primera reseña ---\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "pattern1 = [{'LOWER': 'sound'}, {'LOWER': 'track'}]\n",
        "pattern2 = [{'LOWER': 'video'}, {'IS_PUNCT': True, 'OP': '?'}, {'LOWER': 'game'}] # El ? hace opcional la puntuación\n",
        "\n",
        "matcher.add('GameSoundtrackTerms', [pattern1, pattern2])\n",
        "found_matches = matcher(doc)\n",
        "\n",
        "if found_matches:\n",
        "    print(f\"Se encontraron {len(found_matches)} patrones de interés:\")\n",
        "    for match_id, start, end in found_matches:\n",
        "        span = doc[start:end]\n",
        "        print(f\"- Término encontrado: '{span.text}'\")\n",
        "else:\n",
        "    print(\"No se encontraron los patrones 'sound track' o 'video game' en la primera reseña.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-cPVMvKnwqR",
        "outputId": "f77bca29-e5d4-4c04-b7bc-fe5b27ad825c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Búsqueda de patrones con Matcher en la primera reseña ---\n",
            "Se encontraron 1 patrones de interés:\n",
            "- Término encontrado: 'sound track'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sección 2**: Construcción de un clasificador de sentimientos\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pvuIxujwpGfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1: Importaciones y División de Datos"
      ],
      "metadata": {
        "id": "ZKJQoLWXqcOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "\n",
        "# Dividimos el DataFrame completo en conjuntos de entrenamiento y prueba\n",
        "X = df['review']  # Los textos de las reseñas\n",
        "y = df['label']   # Las etiquetas 'pos' o 'neg'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(f\"\\nDatos divididos: {len(X_train)} para entrenamiento, {len(X_test)} para prueba.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcK0KCIkpCi3",
        "outputId": "fe632dcb-926a-4cf9-95ff-6dd8630a4930"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Datos divididos: 7000 para entrenamiento, 3000 para prueba.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2: Cración y entrenamiento del Pipeline de Machine Learning"
      ],
      "metadata": {
        "id": "0heMM9f6qnYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usaremos el mismo pipeline efectivo: TfidfVectorizer + LinearSVC\n",
        "sentiment_classifier_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', LinearSVC()),\n",
        "])\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento\n",
        "print(\"\\nEntrenando el modelo de clasificación de sentimientos...\")\n",
        "sentiment_classifier_pipeline.fit(X_train, y_train)\n",
        "print(\"¡Modelo entrenado exitosamente!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8mZ8a8fqj0J",
        "outputId": "85f1e66d-19e4-42a1-9a7b-970a651093ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando el modelo de clasificación de sentimientos...\n",
            "¡Modelo entrenado exitosamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3: Evaluación del Desempeño del Modelo"
      ],
      "metadata": {
        "id": "bjhjHvoNq0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Evaluación del modelo en el conjunto de prueba ---\")\n",
        "predictions = sentiment_classifier_pipeline.predict(X_test)\n",
        "\n",
        "# Reporte de clasificación con métricas clave\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(metrics.classification_report(y_test, predictions))\n",
        "\n",
        "# Matriz de confusión para visualizar errores\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(metrics.confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Precisión general del modelo\n",
        "print(f\"Precisión General (Accuracy): {metrics.accuracy_score(y_test, predictions):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQUbmMBgqxLI",
        "outputId": "4c379cd7-feb9-47fa-9323-0c8f49cb68c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluación del modelo en el conjunto de prueba ---\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.87      0.89      0.88      1518\n",
            "         pos       0.89      0.86      0.87      1482\n",
            "\n",
            "    accuracy                           0.88      3000\n",
            "   macro avg       0.88      0.87      0.87      3000\n",
            "weighted avg       0.88      0.88      0.87      3000\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[1353  165]\n",
            " [ 210 1272]]\n",
            "Precisión General (Accuracy): 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4: Pruebas con Nuevas Reseñas"
      ],
      "metadata": {
        "id": "5Iwk8-H2q8wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Probando el modelo con ejemplos nuevos ---\")\n",
        "review_positiva = \"This is the best product I have ever bought, amazing quality and fast shipping!\"\n",
        "review_negativa = \"A complete disappointment. It broke after just one day and the customer service was terrible.\"\n",
        "\n",
        "prediccion_pos = sentiment_classifier_pipeline.predict([review_positiva])[0]\n",
        "prediccion_neg = sentiment_classifier_pipeline.predict([review_negativa])[0]\n",
        "\n",
        "print(f\"Reseña: '{review_positiva}' -> Predicción: {prediccion_pos}\")\n",
        "print(f\"Reseña: '{review_negativa}' -> Predicción: {prediccion_neg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSOe5wZ_q5a_",
        "outputId": "ade0fa63-c1cd-417b-b77e-85a4b9fa8127"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Probando el modelo con ejemplos nuevos ---\n",
            "Reseña: 'This is the best product I have ever bought, amazing quality and fast shipping!' -> Predicción: pos\n",
            "Reseña: 'A complete disappointment. It broke after just one day and the customer service was terrible.' -> Predicción: neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiTR27VgrBoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}