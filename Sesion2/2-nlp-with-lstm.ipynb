{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4efb44e",
   "metadata": {},
   "source": [
    "# NLP con Long-Short Term Memory (LSTM)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion2/2-nlp-with-lstm.ipynb)\n",
    "\n",
    "En este notebook implementaremos un clasificador de noticias en espaÃ±ol utilizando la arquitectura de red LSTM. La idea es tener un punto de referencia para comparar cuando observemos la parte de transformers, por lo que utilizaremos el mismo dataset y tarea de ejemplo. UtilizarÃ©mos las utilidades de tokenizaciÃ³n de huggingface transformers para ayudarnos con esta tarea.\n",
    "\n",
    "#### Referencias\n",
    "- Dataset: https://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news\n",
    "- [Long Short-Term Memory](https://www.researchgate.net/publication/13853244_Long_Short-Term_Memory#fullTextFileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936855e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/requirements.txt && pip install -r requirements.txt\n",
    "!test '{IN_COLAB}' = 'True' && sudo apt-get update -y\n",
    "!test '{IN_COLAB}' = 'True' && sudo apt-get install python3.10 python3.10-distutils python3.10-lib2to3 -y\n",
    "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.11 2\n",
    "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.10 1\n",
    "!test '{IN_COLAB}' = 'True' && pip install lightning datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df40a98",
   "metadata": {},
   "source": [
    "### Cargando el dataset\n",
    "Este es un dataset pequeÃ±o de articulos de noticias en idioma espaÃ±ol con sus respectivas categorÃ­as. El dataset estÃ¡ disponible en el HuggingFace Hub y puede ser fÃ¡cilmente descargado con la librerÃ­a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b91601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['language', 'category', 'newspaper', 'hash', 'text'],\n",
       "    num_rows: 10200\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "dataset = load_dataset('MarcOrfilaCarreras/spanish-news', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a53ebd",
   "metadata": {},
   "source": [
    "Observemos uno de sus registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14abea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language': 'es',\n",
       " 'category': 'play',\n",
       " 'newspaper': 'de_lector_a_lector',\n",
       " 'hash': 'b387bc0a5ad68524c8aa5da489555ca41d5a3575',\n",
       " 'text': 'El coraje de ser, de MÃ³nica CavallÃ©, la aventura del autoconocimiento filosÃ³fico.Todos experimentamos momentos de plenitud vinculados a la expresiÃ³n directa y autÃ©ntica de nosotros mismos: momentos de contemplaciÃ³n de la belleza del mundo en que nuestros sentidos se abren como si lo vieran por primera vez, de intimidad y comuniÃ³n con otro ser humano, de fluidez creativa, de expresiÃ³n confiada y libreâ€¦ Estos momentos permiten intuir lo que puede ser una vida en la que no meramente se existe, sino en la que se vive en todo el sentido de esta palabra.Esta vida solo es posible cuando sabemos quiÃ©nes somos, cuando nos conocemos a nosotros mismos de modo experiencial: no cuando nos llenamos de ideas sobre nosotros, sino cuando nos asentamos en nuestro ser real, mÃ¡s allÃ¡ de nuestras defensas, mÃ¡scaras y falsos yoes.El coraje de ser es una invitaciÃ³n a adentrarnos de forma prÃ¡ctica en el camino del autoconocimiento sapiencial y, mÃ¡s ampliamente, en la vida filosÃ³fica. Busca inspirar y acompaÃ±ar en la apasionante aventura de desnudarnos, reconocer nuestra vulnerabilidad, para poder vernos y ser llenados. Solo esta desnudez lÃºcida da paso a una vida creativa y verdadera; una vida que no solo es una bendiciÃ³n para nosotros mismos, sino tambiÃ©n para los demÃ¡s y para el mundo.MÃ³nica CavallÃ© es doctora en FilosofÃ­a por la Universidad Complutense de Madrid y mÃ¡ster en Ciencias de las Religiones. Ha sido profesora de FilosofÃ­a PrÃ¡ctica y durante varios aÃ±os ha coordinado en la Universidad Complutense de Madrid los seminarios de IntroducciÃ³n FilosÃ³fica al Hinduismo y al Budismo.Trabaja como filÃ³sofa, asesora y dirige la Escuela de FilosofÃ­a Sapiencial. Entre sus obras escritas destacan La sabidurÃ­a recobrada, El arte de ser, y\\xa0La sabidurÃ­a de la no-dualidad, publicadas por KairÃ³s.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e2676",
   "metadata": {},
   "source": [
    "Para los efectos de esta tarea, nos servirÃ¡n el texto y la categorÃ­a naturalmente.\n",
    "\n",
    "A manera general, observemos que tan largos o cortos tienden a ser los textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6642761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto mÃ¡s corto: 501\n",
      "Texto mÃ¡s largo: 204324\n",
      "Longitud promedio: 4218.154509803921\n"
     ]
    }
   ],
   "source": [
    "text_lengths = [len(row['text']) for row in dataset]\n",
    "print(f\"Texto mÃ¡s corto: {min(text_lengths)}\")\n",
    "print(f\"Texto mÃ¡s largo: {max(text_lengths)}\")\n",
    "print(f\"Longitud promedio: {sum(text_lengths) / len(text_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19905224",
   "metadata": {},
   "source": [
    "Estos valores son la cantidad de *caractÃ©res* que tiene las secuencias. Una decisiÃ³n ingenua pero Ãºtil en este momento podrÃ­a ser ajustar la longitud de las secuencias que vamos a usar para el entrenamiento a unos 2000 tokens. Esto podrÃ­a ser suficiente para capturar una porciÃ³n significativa de los textos.\n",
    "\n",
    "## Definiendo el Tokenizer\n",
    "\n",
    "Ahora, vamos a definir el tokenizer para nuestra tarea. Para mantener las cosas simples, vamos a mantener un conteo de palabras y vamos a hacer un corte hasta los primeros 50mil tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d840a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def simple_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã±]+\", \" \", text)\n",
    "    return text.strip().split()\n",
    "\n",
    "# Construimos el vocabulario a partir de conjunto de datos.\n",
    "token_counts = Counter()\n",
    "for text in dataset[\"text\"]:\n",
    "    token_counts.update(simple_tokenizer(text))\n",
    "\n",
    "# 50k-2 porque necesitamos reservar espacio para los dos tokens especiales\n",
    "top_n_tokens = list(token_counts.keys())[:50000-2]\n",
    "vocab = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
    "for token in top_n_tokens:\n",
    "    vocab[token] = len(vocab)\n",
    "\n",
    "def tokenize_text(text, max_length=50):\n",
    "    tokens = simple_tokenizer(text)\n",
    "    ids = [vocab.get(tok, vocab[\"[UNK]\"]) for tok in tokens[:max_length]]\n",
    "    ids += [vocab[\"[PAD]\"]] * (max_length - len(ids))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ce90e",
   "metadata": {},
   "source": [
    "Exploremos ahora el tokenizador obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f037f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: 50000 tokens\n",
      "Primeros 15 tokens:\n",
      "['valladolid', 'misteriosa', 'es', 'el', 'tÃ­tulo', 'del', 'nuevo', 'libro', 'que', 'acaba', 'de', 'publicar', 'la', 'editorial', 'almuzara']\n",
      "15 tokens de en medio:\n",
      "['trabajar', 'primero', 'seis', 'meses', 'guionista', 'antigua', 'city', 'tv', 'despuÃ©s', 'llamÃ³', 'tres', 'medio', 'redactora', 'super', 'pop']\n",
      "Ãšltimos 15 tokens:\n",
      "['risco', 'infecciosas', 'amalia', 'simoni', 'camagÃ¼ey', 'instructor', 'proteinuria', 'disfunciÃ³n', 'endotelial', 'diabÃ©ticos', 'amlodipine', 'bloqueador', 'aml', 'hctz', 'tolerada']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulario: {len(vocab)} tokens\")\n",
    "print(\"Primeros 15 tokens:\")\n",
    "print(f\"{top_n_tokens[:15]}\")\n",
    "print(\"15 tokens de en medio:\")\n",
    "print(f\"{top_n_tokens[1000:1015]}\")\n",
    "print(\"Ãšltimos 15 tokens:\")\n",
    "print(f\"{top_n_tokens[-15:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa0668c",
   "metadata": {},
   "source": [
    "Esta forma de exploraciÃ³n es para darnos una idea de las palabras mÃ¡s utilizadas en el corpus y nos darÃ¡ un indicio de si la tokenizaciÃ³n es adecuada o no. Vemos que tenemos algunos stop words, como artÃ­culos (el, la) y conectores (del, que). Para una tarea de clasificaciÃ³n de texto podrÃ­amos prescindir de estos pero para facilitar las cosas y ya que los demÃ¡s tokens lucen bien, podemos preservarlos.\n",
    "\n",
    "Ahora veamos como convierte el tokenizador una oraciÃ³n muy sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e68c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29340, 157, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenize_text(\"hola mundo\", max_length=8)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e6557",
   "metadata": {},
   "source": [
    "Lo que obtenemos de vuelta son los ids de cada token segÃºn el vocabulario. Ahora algo importante que notamos aquÃ­ es el *padding*, durante el entrenamiento, queremos que las secuencias sean de tamaÃ±o fijo, para asi operar comodamente con matrices. Pero ya vimos que no todos los textos tienen la misma longitud. Entonces que hacer? para los que son mÃ¡s largos que una longitud dada simplemente cortamos, pero para los que son mÃ¡s cortos, debemos *rellenar* lo faltante con un *token especial de relleno o padding*. Y es justo lo que definimos allÃ­, cuando la cadena es inferior a 8 **tokens**, entonces debemos hacer padding hasta que se cumplan los 8.\n",
    "\n",
    "Si queremos saber a que token exactamente hacen referencia estos ids, simplemente revisamos el vocabulario que hemos construido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5049aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'mundo', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_2_token = {v: k for k, v in vocab.items()}\n",
    "[id_2_token[token] for token in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18e433",
   "metadata": {},
   "source": [
    "Claramente vemos los 3 tokens como cadenas independientes (el padding se considera un token independiente).\n",
    "\n",
    "### Definiendo el dataset de pytorch\n",
    "Ahora podemos proceder a definir el dataset. Esto deberÃ­a ser muy sencillo dado que nuestro dataset es pequeÃ±o y ya tenemos el tokenizador listo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca70e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpanishNewsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tokenizer, dataset, seq_length: int = 512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        # Definimos estos dos mapas para facilitarnos la tarea\n",
    "        # de traducir de nombres de categorÃ­a a ids de categorÃ­a.\n",
    "        self.id_2_class_map = dict(enumerate(np.unique(dataset[:]['category'])))\n",
    "        self.class_2_id_map = {v: k for k, v in self.id_2_class_map.items()}\n",
    "        self.num_classes = len(self.id_2_class_map)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, torch.Tensor]:\n",
    "        text, y = self.dataset[index]['text'], self.dataset[index]['category']\n",
    "        y = self.class_2_id_map[y]\n",
    "        data = {'input_ids': torch.tensor(self.tokenizer(text, max_length=self.seq_length))}\n",
    "        data['y'] = torch.tensor(y)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de3493",
   "metadata": {},
   "source": [
    "Ahora instanciaremos el dataset entero. Para este experimento, definiremos un tamaÃ±o mÃ¡ximo de secuencia de 2048 **tokens**. Que segÃºn nuestra intuiciÃ³n arriba, deberÃ­a ser suficiente para la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15200ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512 \n",
    "spanish_news_dataset = SpanishNewsDataset(tokenize_text, dataset, seq_length=max_len)\n",
    "assert len(spanish_news_dataset) == len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d4b0b",
   "metadata": {},
   "source": [
    "Y luego, procedemos a hacer el train-val-test split y crear los dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d7e9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4 if not IN_COLAB else 12\n",
    "train_dataset, val_dataset, test_dataset = random_split(spanish_news_dataset, lengths=[0.8, 0.1, 0.1])\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac44796",
   "metadata": {},
   "source": [
    "## DefiniciÃ³n del modelo LSTM\n",
    "\n",
    "Ahora vamos a configurar un mÃ³dulo pytorch simple para este problema. Vamos ha utilizar los embeddings, que vendrÃ­an siendo los vectores de palabra. Pytorch nos ofrece una capa con la que directamente podemos entrenarlos a partir de los token ids obtenidos. El resto consistirÃ¡ en invocar una capa LSTM seguida de una capa densa para la clasificaciÃ³n.\n",
    "\n",
    "Recordemos que las redes recurrentes como las LSTM por diseÃ±o enlazan todas las dimensiones del vector de entrada, formando asÃ­ la secuencia, la estructura natural que necesitamos representar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d38eb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMBlock(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        return hidden[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f68240",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n del clasificador\n",
    "\n",
    "Finalmente, definimos el modelo en si. Este modelo constarÃ¡ de 3 capas:\n",
    "\n",
    "- La tokenizaciÃ³n, tal como la definimos anteriormente.\n",
    "- El bloque LSTM, que acabamos de decinir.\n",
    "- Una capa densa adicional que servirÃ¡ como clasificador de aquello que nos entregue la capa del transformer.\n",
    "\n",
    "Como este es un LightningModule, aquÃ­ definiremos el resto de funciones utilitarias para el entrenamiento de la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d724f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | lstm       | LSTMBlock          | 13.1 M | train\n",
      "1 | classifier | Sequential         | 200 K  | train\n",
      "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
      "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
      "----------------------------------------------------------\n",
      "13.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.3 M    Total params\n",
      "53.322    Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2040/2040 [00:25<00:00, 79.38it/s, v_num=0, val-loss=0.525, val-acc=0.907, train-loss=0.0621, train-acc=0.985]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2040/2040 [00:26<00:00, 78.38it/s, v_num=0, val-loss=0.525, val-acc=0.907, train-loss=0.0621, train-acc=0.985]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class SpanishNewsClassifierWithLSTM(LightningModule):\n",
    "\n",
    "    def __init__(self, vocab_size: int, num_classes: int, emb_dim: int, hidden_dim: int = 128):\n",
    "        super(SpanishNewsClassifierWithLSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.lstm = LSTMBlock(vocab_size, emb_dim, hidden_dim, num_classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.train_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.test_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.lstm(x)\n",
    "        return self.classifier(embeddings)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch['input_ids'], batch['y']\n",
    "        # print(f\"\\nbatch-idx: {batch_idx}\")\n",
    "        # print(f\"shape of x: {x.shape}\")\n",
    "        # print(torch.max(x, dim=0))\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.train_acc(y_hat, y)\n",
    "        self.log('train-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train-acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch['input_ids'], batch['y']\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.val_acc(y_hat, y)\n",
    "        self.log('val-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val-acc', self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        x, y = batch['input_ids'], batch['y']\n",
    "        y_hat = self(x)\n",
    "        self.test_acc(y_hat, y)\n",
    "        self.log('test-acc', self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def predict_step(self, batch):\n",
    "        x = batch['input_ids']\n",
    "        return self(x)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer =  torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    \n",
    "model = SpanishNewsClassifierWithLSTM(vocab_size=len(vocab) + 1, num_classes=spanish_news_dataset.num_classes, emb_dim=256)\n",
    "\n",
    "tb_logger = TensorBoardLogger('tb_logs', name='LSTMClassifier')\n",
    "callbacks=[EarlyStopping(monitor='train-loss', patience=3, mode='min')]\n",
    "trainer = Trainer(max_epochs=10, devices=1, logger=tb_logger, callbacks=callbacks, precision=\"16-mixed\")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7312d7c",
   "metadata": {},
   "source": [
    "Observemos el proceso de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65f9b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e6dc01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-42fd403edfc8a0e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-42fd403edfc8a0e6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd09d6",
   "metadata": {},
   "source": [
    "Y como es de esperarse, realizaremos la validaciÃ³n contra el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5d52f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:01<00:00, 237.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test-acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9029411673545837     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test-acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9029411673545837    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test-acc': 0.9029411673545837}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06d232",
   "metadata": {},
   "source": [
    "### Haciendo predicciones\n",
    "\n",
    "Finalmente, vamos a hacer uso del modelo y ver que tan bueno es para la clasificaciÃ³n de noticias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff1c989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:01<00:00, 219.44it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model, test_loader)\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "predictions = torch.argmax(predictions, dim=-1)\n",
    "predictions = [spanish_news_dataset.id_2_class_map[pred] for pred in predictions.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bdacb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_string</th>\n",
       "      <th>categorÃ­a</th>\n",
       "      <th>predicciÃ³n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>El Gobierno tiene un plan alternativo para ase...</td>\n",
       "      <td>[5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...</td>\n",
       "      <td>el gobierno tiene un plan alternativo para ase...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>Prevalencia de hipotiroidismo subclÃ­nico y su ...</td>\n",
       "      <td>[34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...</td>\n",
       "      <td>prevalencia de [UNK] [UNK] y su relaciÃ³n con [...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>El Sol, la fuente inagotable de energÃ­a que da...</td>\n",
       "      <td>[5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...</td>\n",
       "      <td>el sol la fuente inagotable de energÃ­a que da ...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>Mondor en la mama. A propÃ³sito de un casoLa en...</td>\n",
       "      <td>[1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...</td>\n",
       "      <td>[UNK] en la [UNK] a propÃ³sito de un [UNK] enfe...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6980</th>\n",
       "      <td>Navantia acaba de firmar con la Marina de Noru...</td>\n",
       "      <td>[1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...</td>\n",
       "      <td>[UNK] acaba de firmar con la marina de noruega...</td>\n",
       "      <td>military</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Tienen una funciÃ³n parecida a los relojes o la...</td>\n",
       "      <td>[440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...</td>\n",
       "      <td>tienen una funciÃ³n parecida a los relojes o la...</td>\n",
       "      <td>tech</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>En Ãºltima instancia, cuando se apagan las luce...</td>\n",
       "      <td>[54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...</td>\n",
       "      <td>en Ãºltima instancia cuando se apagan las luces...</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>La compaÃ±Ã­a francesa Escape International ha p...</td>\n",
       "      <td>[14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...</td>\n",
       "      <td>la compaÃ±Ã­a francesa escape international ha p...</td>\n",
       "      <td>military</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763</th>\n",
       "      <td>El Gobierno busca que Bruselas apruebe un impu...</td>\n",
       "      <td>[5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...</td>\n",
       "      <td>el gobierno busca que bruselas apruebe un impu...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>comentarios 44Cybertron, el planeta de losÂ Tra...</td>\n",
       "      <td>[7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...</td>\n",
       "      <td>comentarios [UNK] el planeta de los transforme...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>La palabra bienquerencia es poco usada, pero e...</td>\n",
       "      <td>[14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...</td>\n",
       "      <td>la palabra [UNK] es poco usada pero existe ind...</td>\n",
       "      <td>religion</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8578</th>\n",
       "      <td>Segunda victoria en el WRC para el finlandÃ©s E...</td>\n",
       "      <td>[1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...</td>\n",
       "      <td>segunda victoria en el [UNK] para el finlandÃ©s...</td>\n",
       "      <td>motor</td>\n",
       "      <td>motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>No hay un equipo mÃ¡s desgraciado que el AlmerÃ­...</td>\n",
       "      <td>[196, 124, 102, 4877, 130, 20027, 10, 5, 23674...</td>\n",
       "      <td>no hay un equipo mÃ¡s desgraciado que el almerÃ­...</td>\n",
       "      <td>sport</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>MÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...</td>\n",
       "      <td>[130, 219, 12, 77, 32819, 12, 10027, 124, 102,...</td>\n",
       "      <td>mÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...</td>\n",
       "      <td>alimentation</td>\n",
       "      <td>alimentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>Evolucion de la vida sexual de la mujer. Fisio...</td>\n",
       "      <td>[1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...</td>\n",
       "      <td>[UNK] de la vida sexual de la mujer [UNK] de l...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto  \\\n",
       "6734  El Gobierno tiene un plan alternativo para ase...   \n",
       "1905  Prevalencia de hipotiroidismo subclÃ­nico y su ...   \n",
       "3049  El Sol, la fuente inagotable de energÃ­a que da...   \n",
       "1772  Mondor en la mama. A propÃ³sito de un casoLa en...   \n",
       "6980  Navantia acaba de firmar con la Marina de Noru...   \n",
       "1589  Tienen una funciÃ³n parecida a los relojes o la...   \n",
       "240   En Ãºltima instancia, cuando se apagan las luce...   \n",
       "7356  La compaÃ±Ã­a francesa Escape International ha p...   \n",
       "6763  El Gobierno busca que Bruselas apruebe un impu...   \n",
       "3341  comentarios 44Cybertron, el planeta de losÂ Tra...   \n",
       "7826  La palabra bienquerencia es poco usada, pero e...   \n",
       "8578  Segunda victoria en el WRC para el finlandÃ©s E...   \n",
       "3456  No hay un equipo mÃ¡s desgraciado que el AlmerÃ­...   \n",
       "5659  MÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...   \n",
       "2184  Evolucion de la vida sexual de la mujer. Fisio...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "6734  [5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...   \n",
       "1905  [34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...   \n",
       "3049  [5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...   \n",
       "1772  [1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...   \n",
       "6980  [1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...   \n",
       "1589  [440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...   \n",
       "240   [54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...   \n",
       "7356  [14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...   \n",
       "6763  [5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...   \n",
       "3341  [7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...   \n",
       "7826  [14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...   \n",
       "8578  [1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...   \n",
       "3456  [196, 124, 102, 4877, 130, 20027, 10, 5, 23674...   \n",
       "5659  [130, 219, 12, 77, 32819, 12, 10027, 124, 102,...   \n",
       "2184  [1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...   \n",
       "\n",
       "                                          tokens_string     categorÃ­a  \\\n",
       "6734  el gobierno tiene un plan alternativo para ase...      politics   \n",
       "1905  prevalencia de [UNK] [UNK] y su relaciÃ³n con [...      medicine   \n",
       "3049  el sol la fuente inagotable de energÃ­a que da ...     astronomy   \n",
       "1772  [UNK] en la [UNK] a propÃ³sito de un [UNK] enfe...      medicine   \n",
       "6980  [UNK] acaba de firmar con la marina de noruega...      military   \n",
       "1589  tienen una funciÃ³n parecida a los relojes o la...          tech   \n",
       "240   en Ãºltima instancia cuando se apagan las luces...          play   \n",
       "7356  la compaÃ±Ã­a francesa escape international ha p...      military   \n",
       "6763  el gobierno busca que bruselas apruebe un impu...      politics   \n",
       "3341  comentarios [UNK] el planeta de los transforme...     astronomy   \n",
       "7826  la palabra [UNK] es poco usada pero existe ind...      religion   \n",
       "8578  segunda victoria en el [UNK] para el finlandÃ©s...         motor   \n",
       "3456  no hay un equipo mÃ¡s desgraciado que el almerÃ­...         sport   \n",
       "5659  mÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...  alimentation   \n",
       "2184  [UNK] de la vida sexual de la mujer [UNK] de l...      medicine   \n",
       "\n",
       "        predicciÃ³n  \n",
       "6734      politics  \n",
       "1905      medicine  \n",
       "3049     astronomy  \n",
       "1772      medicine  \n",
       "6980      military  \n",
       "1589          tech  \n",
       "240           play  \n",
       "7356      military  \n",
       "6763      politics  \n",
       "3341     astronomy  \n",
       "7826      religion  \n",
       "8578         motor  \n",
       "3456         sport  \n",
       "5659  alimentation  \n",
       "2184      medicine  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_indices = test_dataset.indices\n",
    "df = pd.DataFrame(data={\n",
    "    \"texto\": dataset[test_indices]['text'],\n",
    "    \"tokens\": [tokenize_text(v) for v in dataset[test_indices]['text']],\n",
    "    \"categorÃ­a\": dataset[test_indices]['category'],\n",
    "    'predicciÃ³n': predictions\n",
    "}, index=test_indices)\n",
    "\n",
    "df['tokens_string'] = df.tokens.apply(lambda t: ' '.join([id_2_token[i] for i in t]))\n",
    "df = df[[\"texto\", \"tokens\", \"tokens_string\", \"categorÃ­a\", \"predicciÃ³n\"]]\n",
    "df.style.set_table_styles(\n",
    "    [\n",
    "        {'selector': 'td', 'props': [('word-wrap', 'break-word')]}\n",
    "    ]\n",
    ")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c5085d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_string</th>\n",
       "      <th>categorÃ­a</th>\n",
       "      <th>predicciÃ³n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Pues parece que la policÃ­a holandesa se precip...</td>\n",
       "      <td>[2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...</td>\n",
       "      <td>pues parece que la policÃ­a holandesa se precip...</td>\n",
       "      <td>tech</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>El nuevo Consejo de AdministraciÃ³n deÂ Fincanti...</td>\n",
       "      <td>[5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...</td>\n",
       "      <td>el nuevo consejo de administraciÃ³n de [UNK] [U...</td>\n",
       "      <td>military</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>Fuente de la imagen, OtherJune Williams creciÃ³...</td>\n",
       "      <td>[2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...</td>\n",
       "      <td>fuente de la imagen [UNK] williams creciÃ³ junt...</td>\n",
       "      <td>astronomy</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>El Elche espera a Ã“scar Plano. El delantero ma...</td>\n",
       "      <td>[5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...</td>\n",
       "      <td>el elche espera a Ã³scar plano el [UNK] madrile...</td>\n",
       "      <td>sport</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Algunos de los monumentos mÃ¡s famosos del Rein...</td>\n",
       "      <td>[501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...</td>\n",
       "      <td>algunos de los monumentos mÃ¡s famosos del rein...</td>\n",
       "      <td>play</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>Hay anuncios que irremediablemente se quedan a...</td>\n",
       "      <td>[124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...</td>\n",
       "      <td>hay anuncios que irremediablemente se quedan a...</td>\n",
       "      <td>alimentation</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368</th>\n",
       "      <td>Navantia junto a otras 5 grandes empresas, Rep...</td>\n",
       "      <td>[1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...</td>\n",
       "      <td>[UNK] junto a otras grandes empresas [UNK] [UN...</td>\n",
       "      <td>military</td>\n",
       "      <td>motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>La versiÃ³n mÃ¡s accesible del Lucid Air llega p...</td>\n",
       "      <td>[14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...</td>\n",
       "      <td>la versiÃ³n mÃ¡s accesible del [UNK] air llega p...</td>\n",
       "      <td>motor</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>Pedro SÃ¡nchez ha regalado toda una ley de adoc...</td>\n",
       "      <td>[399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...</td>\n",
       "      <td>pedro sÃ¡nchez ha regalado toda una ley de [UNK...</td>\n",
       "      <td>religion</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>Es algo que estÃ¡ sorprendiendo en la red. Mill...</td>\n",
       "      <td>[4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...</td>\n",
       "      <td>es algo que estÃ¡ sorprendiendo en la red millo...</td>\n",
       "      <td>religion</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9900</th>\n",
       "      <td>La Edad Media no fue la Ã©poca maloliente y suc...</td>\n",
       "      <td>[14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...</td>\n",
       "      <td>la edad media no fue la Ã©poca [UNK] y sucia qu...</td>\n",
       "      <td>economy</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>La Ãºltima generaciÃ³n de videoconsolas lanzadas...</td>\n",
       "      <td>[14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...</td>\n",
       "      <td>la Ãºltima generaciÃ³n de videoconsolas lanzadas...</td>\n",
       "      <td>play</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>La necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...</td>\n",
       "      <td>[14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...</td>\n",
       "      <td>la necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...</td>\n",
       "      <td>economy</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>Â¿QuÃ© es la farmacologÃ­a? Ciencia que estudia l...</td>\n",
       "      <td>[1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...</td>\n",
       "      <td>quÃ© es la [UNK] ciencia que estudia los fÃ¡rmac...</td>\n",
       "      <td>medicine</td>\n",
       "      <td>military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>El Ayuntamiento de Palma ha colocado este mart...</td>\n",
       "      <td>[5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...</td>\n",
       "      <td>el ayuntamiento de palma ha colocado este mart...</td>\n",
       "      <td>religion</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texto  \\\n",
       "1120  Pues parece que la policÃ­a holandesa se precip...   \n",
       "7473  El nuevo Consejo de AdministraciÃ³n deÂ Fincanti...   \n",
       "2765  Fuente de la imagen, OtherJune Williams creciÃ³...   \n",
       "4142  El Elche espera a Ã“scar Plano. El delantero ma...   \n",
       "689   Algunos de los monumentos mÃ¡s famosos del Rein...   \n",
       "5835  Hay anuncios que irremediablemente se quedan a...   \n",
       "7368  Navantia junto a otras 5 grandes empresas, Rep...   \n",
       "9001  La versiÃ³n mÃ¡s accesible del Lucid Air llega p...   \n",
       "7846  Pedro SÃ¡nchez ha regalado toda una ley de adoc...   \n",
       "8103  Es algo que estÃ¡ sorprendiendo en la red. Mill...   \n",
       "9900  La Edad Media no fue la Ã©poca maloliente y suc...   \n",
       "786   La Ãºltima generaciÃ³n de videoconsolas lanzadas...   \n",
       "9576  La necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...   \n",
       "2098  Â¿QuÃ© es la farmacologÃ­a? Ciencia que estudia l...   \n",
       "7888  El Ayuntamiento de Palma ha colocado este mart...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1120  [2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...   \n",
       "7473  [5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...   \n",
       "2765  [2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...   \n",
       "4142  [5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...   \n",
       "689   [501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...   \n",
       "5835  [124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...   \n",
       "7368  [1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...   \n",
       "9001  [14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...   \n",
       "7846  [399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...   \n",
       "8103  [4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...   \n",
       "9900  [14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...   \n",
       "786   [14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...   \n",
       "9576  [14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...   \n",
       "2098  [1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...   \n",
       "7888  [5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...   \n",
       "\n",
       "                                          tokens_string     categorÃ­a  \\\n",
       "1120  pues parece que la policÃ­a holandesa se precip...          tech   \n",
       "7473  el nuevo consejo de administraciÃ³n de [UNK] [U...      military   \n",
       "2765  fuente de la imagen [UNK] williams creciÃ³ junt...     astronomy   \n",
       "4142  el elche espera a Ã³scar plano el [UNK] madrile...         sport   \n",
       "689   algunos de los monumentos mÃ¡s famosos del rein...          play   \n",
       "5835  hay anuncios que irremediablemente se quedan a...  alimentation   \n",
       "7368  [UNK] junto a otras grandes empresas [UNK] [UN...      military   \n",
       "9001  la versiÃ³n mÃ¡s accesible del [UNK] air llega p...         motor   \n",
       "7846  pedro sÃ¡nchez ha regalado toda una ley de [UNK...      religion   \n",
       "8103  es algo que estÃ¡ sorprendiendo en la red millo...      religion   \n",
       "9900  la edad media no fue la Ã©poca [UNK] y sucia qu...       economy   \n",
       "786   la Ãºltima generaciÃ³n de videoconsolas lanzadas...          play   \n",
       "9576  la necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...       economy   \n",
       "2098  quÃ© es la [UNK] ciencia que estudia los fÃ¡rmac...      medicine   \n",
       "7888  el ayuntamiento de palma ha colocado este mart...      religion   \n",
       "\n",
       "     predicciÃ³n  \n",
       "1120       play  \n",
       "7473    economy  \n",
       "2765   religion  \n",
       "4142    economy  \n",
       "689        tech  \n",
       "5835  astronomy  \n",
       "7368      motor  \n",
       "9001    economy  \n",
       "7846   politics  \n",
       "8103  astronomy  \n",
       "9900  astronomy  \n",
       "786        tech  \n",
       "9576    fashion  \n",
       "2098   military  \n",
       "7888   politics  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = df[df['categorÃ­a'] != df['predicciÃ³n']]\n",
    "errors.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88103e5e",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- En este caso tenemos una tarea de clasificaciÃ³n de texto de mÃºltiples clases.\n",
    "- Estamos usando un bloque LSTM como featurizer, es decir lo usamos para extraer features de las secuencias de entrada con las cuales harÃ©mos predicciones luego.\n",
    "- NÃ³tese que de las capas LSTM, solo nos interesa la Ãºltima, ya que esta recupera todas las operaciones enalazadas anteriores.\n",
    "- Observamos que el modelo toma su tiempo en entrenar, esto es natural debido al diseÃ±o de las LSTM, donde por cada paso de tiempo se debe computar un gradiente, por lo que el computo es mucho mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73526f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icesi-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
