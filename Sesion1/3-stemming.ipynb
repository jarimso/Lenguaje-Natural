{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion1/3-stemming.ipynb)\n",
    "\n",
    "De un modo resumido, stemming consiste en encontrar la palabra más larga posible que pueda servir como raíz para otras palabras. Puede ser mucho más complejo que esto, pero en esencia se trata de formar familias de palabras similares que tienden a compartir una razíz común, el stem.\n",
    "\n",
    "En este notebook también vamos a explorar otra de las librerías más populares para el NLP clásico: NLTK.\n",
    "\n",
    "## Referencias\n",
    "* [NLP - Natural Language Processing With Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python)\n",
    "* [Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test '{IN_COLAB}' = 'True' && wget  https://github.com/Ohtar10/icesi-nlp/raw/refs/heads/main/requirements.txt && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porter Stemmer\n",
    "Este es uno de los algoritmos de stemming más comunes. Desarrollado por [Martin Porter](https://en.wikipedia.org/wiki/Martin_Porter)\n",
    "\n",
    "Observemos por ejemplo este conjunto de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2025.7.34-cp39-cp39-macosx_11_0_arm64.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/j.ricardomunoz/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: tqdm in /Users/j.ricardomunoz/Library/Python/3.9/lib/python/site-packages (from nltk) (4.67.1)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[K     |████████████████████████████████| 307 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.5.1 nltk-3.9.1 regex-2025.7.34\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "words = ['run', 'runner', 'ran', 'runs', 'easily', 'fairly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, si usamos el algoritmo de porter, podrémos obtener los podemos obtener una visualización inicial de posibles raices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run                 --> run\n",
      "runner              --> runner\n",
      "ran                 --> ran\n",
      "runs                --> run\n",
      "easily              --> easili\n",
      "fairly              --> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(f\"{word:{20}}--> {p_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que `run` y `runs` comparten la misma raíz `run`.\n",
    "\n",
    "Hay algo a tener en cuenta: El porter stemmer original fue desarrollado para el idioma inglés ya que fue implementado siguiendo ciertas reglas consistentes de dicho idioma, por lo que no podríamos aplicarlo tal cual al español.\n",
    "\n",
    "Sin embargo, a partir de este stemmer, el método Snowball fue desarrollado para muchos otros lenguajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowball\n",
    "Snowball es entonces una mejora sobre el porter stemmer, incluyendo soporte para otros lenguajes. Por motivos de completitud y comparación, continuemos con inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run                 --> run\n",
      "runner              --> runner\n",
      "ran                 --> ran\n",
      "runs                --> run\n",
      "easily              --> easili\n",
      "fairly              --> fair\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "     print(f\"{word:{20}}--> {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observermos la diferencia en la palabra `fair` que es mejor y mucho más general, realmente las palabras `fair` y `fairly` son ambas válidas y comparten la misma raíz.\n",
    "\n",
    "Ahora observemos como se comporta con un conjunto de palabras un poco más difícil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def stem(words :List[str], stemmer) -> List[str]:\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>porter</th>\n",
       "      <th>snowball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>generous</td>\n",
       "      <td>gener</td>\n",
       "      <td>generous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generation</td>\n",
       "      <td>gener</td>\n",
       "      <td>generat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generously</td>\n",
       "      <td>gener</td>\n",
       "      <td>generous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generate</td>\n",
       "      <td>gener</td>\n",
       "      <td>generat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word porter  snowball\n",
       "0    generous  gener  generous\n",
       "1  generation  gener   generat\n",
       "2  generously  gener  generous\n",
       "3    generate  gener   generat"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Notice these words share roots but mean totally different things\n",
    "words = ['generous', 'generation', 'generously', 'generate']\n",
    "with_porter = stem(words, p_stemmer)\n",
    "with_snowball = stem(words, s_stemmer)\n",
    "\n",
    "word_list = list(zip(words, with_porter, with_snowball))\n",
    "words_df = pd.DataFrame(word_list, columns=['word', 'porter', 'snowball'])\n",
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podemos observar como snowball es mejor que porter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
